# -*- coding: utf-8 -*-
"""aula3_webscrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1skmOObQAkEgQS07pj92lQPqdfMdAr27i
"""

##Configuração de um raspador (scraper)
import requests ##para trabalhar com web
import re ##regex
import json ##converte arquivos para json
from bs4 import BeautifulSoup ##raspador

import os #Trabalha com o sistema operacional do computador

!pip install bs4

!pip install re

!pip install requests

result = requests.get('https://globoesporte.globo.com/cartola-fc/')

#result = requests.get()
# result = requests.get('https://globoesporte.globo.com/cartola-fc/')
result = requests.get('https://web.archive.org/web/20150320072958/http://allrecipes.com.br/receita/4658/bolinho-de-arroz-italiano--arancini-.aspx?o_is=Hub_TopRecipe_1')

result

src = result.content
#src

soup = BeautifulSoup(src, 'lxml')

soup

soup.find('div')

soup.find('img')

imagem_receita = soup.find('div').find_all("span", {'itemprop':'image'})
#ingredients = soup.(".recipeIngredients").find_all("section")
for a in imagem_receita:
  imagem_receita = a.text
imagem_receita

nome_receita = soup.find('div').find_all("span", {'itemprop':'name'})
#ingredients = soup.(".recipeIngredients").find_all("section")
for a in nome_receita:
  nome_receita = a.text
nome_receita

soup.find('div').find_all("ol")

descricao = soup.find('div').find_all("span", {'itemprop':'description'})
#ingredients = soup.(".recipeIngredients").find_all("section")
for a in descricao:
  descricao = a.text
descricao

ingredients = soup.find('div').find_all("span", {'itemprop':'ingredients'})
#ingredients = soup.(".recipeIngredients").find_all("section")
ingredients

ingredients_list = []
for a in ingredients:
    ingredients_list.append(a.text)
print(ingredients_list)

receita = soup.find('div').find_all("ol", {'itemprop':'recipeInstructions'})
for a in receita:
    receita = a.text
print(receita)

##Convertendo o script em um dict
receita_dict = {'ID': 1,
                'Título': nome_receita,
                'Descrição': descricao,
                'Ingredientes': ingredients_list,
                'Receita': receita}
receita_dict

#Convertendo para JSON
#ensure_ascii garante que não terá mudança de encoding
receita_json = json.dumps(receita_dict, ensure_ascii=False)
print(receita_json)

!pip install pyttsx3

def ferramenta_receitas(endereco):

  result = requests.get(endereco)
  if result.status_code == 200:
      src = result.content
      soup = BeautifulSoup(src, 'lxml')
      nome_receita = soup.find('div').find_all('span', {'itemprop':'name'})
      for a in nome_receita:
          nome_receita = a.text
      descricao = soup.find('div').find_all('span', {'itemprop':'description'})
      for a in descricao:
          descricao = a.text
      ingredients = soup.find('div').find_all('span', {'itemprop':'ingredients'})
      ingredients_list = []
      for a in ingredients:
          ingredients_list.append(a.text)
      receita = soup.find('div').find_all('ol',{'itemprop':'recipeInstructions'}) 
      for a in receita:
          receita = a.text
      receita_dict = {'ID': 1,
                'Título': nome_receita,
                'Descrição': descricao,
                'Ingredientes': ingredients_list,
                'Receita': receita}

      return(receita_dict)
     
  else: print('Página não pode ser raspada')

ferramenta_receitas('https://web.archive.org/web/20150315020739/http://allrecipes.com.br/receita/4420/nega-maluca.aspx?o_is=HS_Image_1')

link_receitas = ['https://web.archive.org/web/20150320072958/http://allrecipes.com.br/receita/4658/bolinho-de-arroz-italiano--arancini-.aspx?o_is=Hub_TopRecipe_1',
                 'https://web.archive.org/web/20150315020739/http://allrecipes.com.br/receita/4420/nega-maluca.aspx?o_is=HS_Image_1']
for a in link_receitas:
     temp = ferramenta_receitas(a)
     print(temp)

#Estruturação e Importação de dados do python para o Mongoo DB

!pip install pymongo
!pip install dnspython
!pip install pymongo[srv]
!pip install psycopg2

import pymongo

client = pymongo.MongoClient("mongodb+srv://loslhp:loslhp10@cluster0.zxsek.mongodb.net/?retryWrites=true&w=majority")
db = client.scrapper
client.server_info()

import pandas as pd
#import collection #From Python Standard Library
#import bson
#from bson.raw_bson import RawBSONDocument

teste = ferramenta_receitas('https://web.archive.org/web/20150315020739/http://allrecipes.com.br/receita/4420/nega-maluca.aspx?o_is=HS_Image_1')

scapper = db['scrapper']

scapper.insert_one('teste')

collection = db.scrapper
data = pd.DataFrame(list(collection.find()))
data

def ferramenta_receitas(endereco, upload_mongo=False):

    result = requests.get(endereco)
    if result.status_code == 200:
        src = result.content
        soup = BeautifulSoup(src, 'lxml')
        nome_receita = soup.find('div').find_all('span',
                {'itemprop': 'name'})
        for a in nome_receita:
            nome_receita = a.text
        descricao = soup.find('div').find_all('span',
                {'itemprop': 'description'})
        for a in descricao:
            descricao = a.text
        ingredients = soup.find('div').find_all('span',
                {'itemprop': 'ingredients'})
        ingredients_list = []
        for a in ingredients:
            ingredients_list.append(a.text)
        receita = soup.find('div').find_all('ol',
                {'itemprop': 'recipeInstructions'})
        for a in receita:
            receita = a.text
        receita_dict = {
            'ID': 1,
            'Título': nome_receita,
            'Descrição': descricao,
            'Ingredientes': ingredients_list,
            'Receita': receita,
            }

        return receita_dict

        if upload_mongo == False:
            return receita_dict
        else:
            client = \
                pymongo.MongoClient('mongodb+srv://loslhp:loslhp10@cluster0.zxsek.mongodb.net/?retryWrites=true&w=majority'
                                    )
            db = client.scrapper
            client.server_info()

            scrapper = db['scrapper']
            scrapper.insert_one(receita_dict)
            return (receita_dict)
    else:

        print('Página não pode ser raspada')

ferramenta_receitas('https://web.archive.org/web/20150315020739/http://allrecipes.com.br/receita/4420/nega-maluca.aspx?o_is=HS_Image_1', 
                    upload_mongo = True)

def ferramenta_receitas(endereco, upload_mongo = False):
    result = requests.get(endereco)
    if result.status_code == 200:
        src = result.content
        soup = BeautifulSoup(src, 'lxml')
        nome_receita = soup.find('div').find_all("span", {'itemprop':'name'})
        for a in nome_receita:
            nome_receita = a.text
        descricao = soup.find('div').find_all("span", {'itemprop':"description"})
        for a in descricao:
            descricao = a.text
        ingredients = soup.find('div').find_all("span", {'itemprop':'ingredients'})
        ingredients_list = []
        for a in ingredients:
            ingredients_list.append(a.text)
        receita = soup.find('div').find_all("ol", {'itemprop':'recipeInstructions'})
        for a in receita:
            receita = a.text
        receita_dict = {'ID': 1,
       'Titulo': nome_receita,
       'Descrição': descricao,
       'Ingredientes': ingredients_list,
       'Receita': receita}
        
        if upload_mongo == False:
            return(receita_dict)
        else:
            client = pymongo.MongoClient('mongodb+srv://loslhp:loslhp10@cluster0.zxsek.mongodb.net/?retryWrites=true&w=majority')
            db = client.scrapper
            client.server_info()
                
            scrapper = db['scrapper']
            scrapper.insert_one(receita_dict)
            return(receita_dict)
            
    else: print('Página não pode ser raspada')

ferramenta_receitas('https://web.archive.org/web/20150320053530/http://allrecipes.com.br/receita/8067/bolo-pudim-de-chocolate.aspx?o_is=LV', 
                    upload_mongo = True)

collection = db.scrapper
data = pd.DataFrame(list(collection.find()))
data

imagem_receita = soup.find('div').find_all("span", {'itemprop':'image'})
#ingredients = soup.(".recipeIngredients").find_all("section")
for a in imagem_receita:
  imagem_receita = a.text
imagem_receita